{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Demonstration Selection\n",
    "\n",
    "Select the best example to use as a demonstatration in the few-prompt tests.\n",
    "\n",
    "The goal is to find the document that not only contains a good quantity of the entity to be extracted but also a good divercity in the types of entties to be extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.reader import read_lusa\n",
    "from src.prompts import Prompter\n",
    "\n",
    "ROOT = Path().resolve().parent\n",
    "DATA_PATH = ROOT / \"resources\" / \"lusa_news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lusa = read_lusa(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DOCS_IDS = [\n",
    "    \"lusa_189\",\n",
    "    \"lusa_100\",\n",
    "    \"lusa_197\",\n",
    "    \"lusa_161\",\n",
    "    \"lusa_116\",\n",
    "    \"lusa_176\",\n",
    "    \"lusa_195\",\n",
    "    \"lusa_173\",\n",
    "    \"lusa_172\",\n",
    "    \"lusa_13\",\n",
    "    \"lusa_142\",\n",
    "    \"lusa_126\",\n",
    "    \"lusa_188\",\n",
    "    \"lusa_107\",\n",
    "    \"lusa_203\",\n",
    "    \"lusa_191\",\n",
    "    \"lusa_170\",\n",
    "    \"lusa_133\",\n",
    "    \"lusa_179\",\n",
    "    \"lusa_155\",\n",
    "]\n",
    "\n",
    "# remove documents used in the selection of the prompts\n",
    "lusa = [doc for doc in lusa if doc.id not in SAMPLE_DOCS_IDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_document(documents, entities, attribute):\n",
    "    best_doc = None\n",
    "    max_n_entities, max_n_classes = None, None\n",
    "    for doc in documents:\n",
    "        \n",
    "        doc_classes = set([\n",
    "            getattr(entity, attribute)\n",
    "            for entity in getattr(doc, entities)\n",
    "            if hasattr(entity, str(attribute))\n",
    "        ])\n",
    "        \n",
    "        n_doc_classes = len(doc_classes)\n",
    "        n_entities = len(getattr(doc, entities))\n",
    "\n",
    "        if best_doc is None:\n",
    "            best_doc = doc\n",
    "            max_n_entities = n_entities\n",
    "            max_n_classes = n_doc_classes\n",
    "            continue\n",
    "        \n",
    "        if n_doc_classes >= max_n_classes and n_entities >= max_n_entities:\n",
    "            max_n_entities = n_entities\n",
    "            max_n_classes = n_doc_classes\n",
    "            best_doc = doc\n",
    "    return best_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event classes: {'State', 'I_Action', 'Reporting', 'Perception', 'I_State', 'Aspectual', 'Occurrence'}\n"
     ]
    }
   ],
   "source": [
    "event_classes = set(event.class_ for doc in lusa for event in doc.events if hasattr(event, \"class_\"))\n",
    "print(\"Event classes:\", event_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document: 46\n"
     ]
    }
   ],
   "source": [
    "n_event_per_doc = [len(doc.events) for doc in lusa] \n",
    "max_events = max(n_event_per_doc)\n",
    "\n",
    "print(\"Max events per document:\", max_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document class count: Counter({'Occurrence': 20, 'State': 18, 'Reporting': 6, 'I_Action': 1, 'I_State': 1})\n"
     ]
    }
   ],
   "source": [
    "max_events_idx = np.argmax(n_event_per_doc)\n",
    "doc_max_events = lusa[max_events_idx]\n",
    "\n",
    "max_doc_class_count = Counter([event.class_ for event in doc_max_events.events if hasattr(event, \"class_\")])\n",
    "print(\"Max events per document class count:\", max_doc_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_doc = get_best_document(lusa, \"events\", \"class_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with the most events and number of classes: lusa_119\n"
     ]
    }
   ],
   "source": [
    "print(\"Document with the most events and number of classes:\", best_doc.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:\n",
      "Extract all event triggers.\n",
      "\n",
      "Example:\n",
      "\tInput:\n",
      "\t\"Covi-19: Governo de estado australiano pede desculpa por erros em quarentenas em hotéis\n",
      "O líder do governo do estado australiano de Victoria pediu hoje desculpa pelos erros do programa de quarentena em dois hotéis que levaram à maioria das mortes por covid-19 no país.\n",
      "Após a divulgação do relatório de investigação, o primeiro-ministro de Victoria, Dan Andrews, explicou que o sistema de quarentena tinha sido implementado rapidamente e sem um livro de regras pandémico.\n",
      "\"Quero pedir desculpa à comunidade vitoriana pelos erros muito claros que foram cometidos neste programa\", disse Andrews.\n",
      "O fraco controlo em dois hotéis de quarentena desencadearam uma onda de infeções na segunda maior cidade da Austrália, enquanto o resto do país tinha estado em grande parte livre de vírus.\n",
      "Das 908 mortes australianas por covid-19, 820 morreram em Victoria.\n",
      "A polícia fornece agora segurança nos hotéis de quarentena de Melbourne, algo que neste dois oitos foram feito por seguranças privados.\n",
      "o estado de Victoria não tinha registada um caso de transmissão comunitária há 52 dias e o aeroporto de Melbourne começou a aceitar chegadas internacionais este mês pela primeira vez desde o início de julho.\"\n",
      "\tOutput:\n",
      "\t[\"pediu\", \"desculpa\", \"erros\", \"levaram\", \"mortes\", \"quarentena\", \"divulga\\u00e7\\u00e3o\", \"explicou\", \"implementado\", \"investiga\\u00e7\\u00e3o\", \"quarentena\", \"Quero\", \"pedir\", \"desculpa\", \"erros\", \"cometidos\", \"disse\", \"fraco controlo\", \"quarentena\", \"desencadearam\", \"infe\\u00e7\\u00f5es\", \"estado em grande parte livre\", \"morreram\", \"fornece\", \"seguran\\u00e7a\", \"quarentena\", \"feito\", \"registada\", \"caso\", \"transmiss\\u00e3o comunit\\u00e1ria\", \"come\\u00e7ou\", \"aceitar\", \"chegadas internacionais\", \"programa\", \"sistema\", \"programa\", \"que\", \"mortes australianas\", \"algo\"]\n",
      "\n",
      "Format:\n",
      "JSON-parseable list of strings.\n",
      "\n",
      "Input:\n",
      "\"$text\"\n",
      "\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation = [ent.text for ent in best_doc.events]\n",
    "prompter = Prompter(entity=\"event triggers\", example=best_doc)\n",
    "print(prompter.template.template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timex classes: {'Date', 'Time', 'Duration', 'Set'}\n"
     ]
    }
   ],
   "source": [
    "timex_classes = set(timex.time_type for doc in lusa for timex in doc.timexs if hasattr(timex, \"time_type\"))\n",
    "print(\"Timex classes:\", timex_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document: 9\n"
     ]
    }
   ],
   "source": [
    "n_timex_per_doc = [len(doc.timexs) for doc in lusa] \n",
    "max_timex = max(n_timex_per_doc)\n",
    "\n",
    "print(\"Max events per document:\", max_timex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document class count: Counter({'Time': 4, 'Date': 3, 'Duration': 2})\n"
     ]
    }
   ],
   "source": [
    "max_timex_idx = np.argmax(n_timex_per_doc)\n",
    "doc_max_timexs = lusa[max_timex_idx]\n",
    "\n",
    "max_doc_class_count = Counter([timex.time_type for timex in doc_max_timexs.timexs if hasattr(timex, \"time_type\")])\n",
    "print(\"Max events per document class count:\", max_doc_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with the most timexs and number of classes: lusa_11\n",
      "Number of timexs: 9\n",
      "Number of timex classes: 3\n"
     ]
    }
   ],
   "source": [
    "best_doc = get_best_document(lusa, \"timexs\", \"time_type\")\n",
    "print(\"Document with the most timexs and number of classes:\", best_doc.id)\n",
    "print(\"Number of timexs:\", len(best_doc.timexs))\n",
    "print(\"Number of timex classes:\", len(set([timex.time_type for timex in best_doc.timexs if hasattr(timex, \"time_type\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:\n",
      "Extract all time expressions.\n",
      "\n",
      "Example:\n",
      "\tInput:\n",
      "\t\"Autoridades moçambicanas apreendem mais de uma tonelada de caranguejo\n",
      "A fiscalização marítima moçambicana apreendeu 1.100 quilos de caranguejo, no centro do país, em menos de uma semana, capturado na \"época de veda\", quando é proibido apanhar a espécie, disse hoje à Lusa fonte das autoridades.\n",
      "A última apreensão aconteceu no sábado quando as autoridades descobriram uma embarcação com 600 quilos de caranguejo.\n",
      "“Estamos a apreender caranguejo e embarcações e os responsáveis incorrem em pesadas multas, caso sejam neutralizados”, explicou o chefe da fiscalização, César Maphossa.\n",
      "No sábado, os tripulantes abandonaram o barco, fundeado nos arredores da cidade da Beira, centro de Moçambique, quando se aperceberam da chegada dos fiscais.\n",
      "A embarcação foi confiscada e os caranguejos, dissimulados em caixas, foram posteriormente devolvidos ao seu habitat natural, no mangal do rio Maria, arredores da capital provincial de Sofala.\n",
      "A apreensão ocorreu menos de uma semana após as autoridades terem descoberto outros 500 quilos de caranguejo capturado também no período de proibição, que começou em setembro e decorre até final do ano.\n",
      "As épocas de veda visam a manutenção e exploração sustentável de espécies marinhas, dando-lhes um período sem captura que permita a recuperação das respetivas populações.\"\n",
      "\tOutput:\n",
      "\t[\"em menos de uma semana\", \"s\\u00e1bado\", \"s\\u00e1bado\", \"setembro\", \"final do ano\", \"menos de uma semana\", \"30 nov 2020\", \"\\u00e9poca de veda\", \"\\u00e9pocas de veda\"]\n",
      "\n",
      "Format:\n",
      "JSON-parseable list of strings.\n",
      "\n",
      "Input:\n",
      "\"$text\"\n",
      "\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation = [ent.text for ent in best_doc.timexs]\n",
    "prompter = Prompter(entity=\"time expressions\", example=best_doc)\n",
    "print(prompter.template.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant classes: {'Per', 'Fac', 'Nat', 'Other', 'Obj', 'Loc', 'Org'}\n"
     ]
    }
   ],
   "source": [
    "participant_classes = set(participant.participant_type_domain for doc in lusa for participant in doc.participants if hasattr(participant, \"participant_type_domain\"))\n",
    "print(\"Participant classes:\", participant_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document: 48\n"
     ]
    }
   ],
   "source": [
    "n_part_per_doc = [len(doc.participants) for doc in lusa] \n",
    "max_part = max(n_part_per_doc)\n",
    "\n",
    "print(\"Max events per document:\", max_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max events per document class count: Counter({'Per': 17, 'Loc': 15, 'Org': 8, 'Nat': 6, 'Other': 2})\n"
     ]
    }
   ],
   "source": [
    "max_part_idx = np.argmax(n_part_per_doc)\n",
    "doc_max_parts = lusa[max_part_idx]\n",
    "\n",
    "max_doc_class_count = Counter([part.participant_type_domain for part in doc_max_parts.participants if hasattr(part, \"participant_type_domain\")])\n",
    "print(\"Max events per document class count:\", max_doc_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with the most participants and number of classes: lusa_156\n",
      "Number of participants: 47\n",
      "Number of participants classes: 6\n"
     ]
    }
   ],
   "source": [
    "best_doc = get_best_document(lusa, \"participants\", \"participant_type_domain\")\n",
    "print(\"Document with the most participants and number of classes:\", best_doc.id)\n",
    "print(\"Number of participants:\", len(best_doc.participants))\n",
    "print(\"Number of participants classes:\", len(set([part.participant_type_domain for part in best_doc.participants if hasattr(part, \"participant_type_domain\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:\n",
      "Extract all participants.\n",
      "\n",
      "Example:\n",
      "\tInput:\n",
      "\t\"Homem armado faz vários reféns dentro de um banco na Geórgia\n",
      "Um homem armado fez hoje à tarde vários reféns, ainda em número incerto, dentro das instalações de um banco na Geórgia, informaram as autoridades desta ex-república soviética.\n",
      "O Ministério do Interior da Geórgia não precisou, até ao momento, quantas pessoas foram feitas reféns dentro do banco, localizado na cidade de Zugdidi (região oeste), ou quais são as exigências do agressor.\n",
      "A polícia isolou, entretanto, a zona onde fica a sucursal bancária e montou uma operação \"para neutralizar o agressor\", informou o ministério num comunicado.\n",
      "A televisão estatal da Geórgia, a Mtavari TV, noticiou que o sequestrador está armado com uma granada de mão e exige 500.000 dólares (cerca de 420.000 euros) em dinheiro.\n",
      "A Mtavari TV conseguiu falar com um dos reféns que indicou que o agressor mantém 19 pessoas dentro das instalações bancárias.\n",
      "O canal de televisão também divulgou um vídeo que mostra uma sala com pessoas sentadas no chão e um homem vestido com um uniforme militar, de rosto coberto, e armado com uma espingarda.\"\n",
      "\tOutput:\n",
      "\t[\"um comunicado\", \"Um homem armado\", \"v\\u00e1rios ref\\u00e9ns\", \"n\\u00famero incerto\", \"as instala\\u00e7\\u00f5es\", \"a Ge\\u00f3rgia\", \"as autoridades\", \"esta ex-rep\\u00fablica sovi\\u00e9tica\", \"O Minist\\u00e9rio do Interior\", \"a Ge\\u00f3rgia\", \"quantas pessoas\", \"ref\\u00e9ns\", \"o banco,\", \"a cidade de Zugdidi (regi\\u00e3o oeste)\", \"quais\", \"o agressor\", \"A pol\\u00edcia\", \"a zona\", \"onde\", \"a sucursal banc\\u00e1ria\", \"o agressor\", \"o minist\\u00e9rio\", \"A televis\\u00e3o estatal\", \"a Mtavari TV\", \"o sequestrador\", \"uma granada de m\\u00e3o\", \"500.000 d\\u00f3lares (cerca de 420.000 euros)\", \"dinheiro\", \"A Mtavari TV\", \"um\", \"os ref\\u00e9ns\", \"o agressor\", \"19 pessoas\", \"as instala\\u00e7\\u00f5es banc\\u00e1rias\", \"O canal de televis\\u00e3o\", \"um v\\u00eddeo\", \"uma sala\", \"pessoas\", \"o ch\\u00e3o\", \"um homem\", \"um uniforme militar\", \"rosto\", \"uma espingarda\", \"um banco\", \"que\", \"a Ge\\u00f3rgia\", \"que\"]\n",
      "\n",
      "Format:\n",
      "JSON-parseable list of strings.\n",
      "\n",
      "Input:\n",
      "\"$text\"\n",
      "\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotation = [ent.text for ent in best_doc.participants]\n",
    "prompter = Prompter(entity=\"participants\", example=best_doc)\n",
    "print(prompter.template.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
