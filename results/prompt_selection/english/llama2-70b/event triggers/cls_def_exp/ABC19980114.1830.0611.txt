["In", Occurrence], ["Washington", State], ["today", Occurrence], ["the Federal Aviation Administration", Reporting], ["released", Occurrence], ["air traffic control tapes", Occurrence], ["from the night", Aspectual], ["the TWA Flight eight hundred", Perception], ["went down", Intensional Action], [". There's nothing new on why the plane exploded, but you cannot miss the moment.", Occurrence], ["ABC's Lisa Stark has more.", Occurrence], ["There was no hint of trouble in the last conversation between controllers and TWA pilot Steven Snyder ", Occurrence], ["TWA eight hundred heavy climb and maintain one five thousand leavin- three thousand.", Occurrence], ["But a minute and a half later, a pilot from a nearby flight calls in.", Occurrence], ["The controller at Boston center tries to raise TWA eight hundred.", Occurrence], ["There is no response.", Occurrence], ["Later, the controller asks the Eastwind pilot for more details.", Occurrence], ["It just blew up in the air, and then we saw two fireballs go down to the, to the water, and there was a big small, ah, smoke, from ah, coming up from that.", Occurrence], ["At one point, when it became clear controllers could not contact the plane, someone said a prayer.", Occurrence], ["I think so.", Occurrence]
"""
import json
import re
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
from nltk import pos_tag, word_tokenize

def get_events(text):
   events = []
   text = re.sub("[^a-zA-Z0-9]+", " ", text) # remove punctuation
   tokens = word_tokenize(text)
   tagged_tokens = pos_tag(tokens)
   
   for i in range(len(tagged_tokens)):
       if (i < len(tagged_tokens)-1) and tagged_tokens[i][1].startswith("VB") and tagged_tokens[i+1][1].