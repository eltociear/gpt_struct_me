["Elco Industries Inc.", "Occurrence"], ["net income", "Reporting"], ["$1.65 a share", "Aspectual"], ["Rockford, Ill.", "State"], ["fasteners", "Intensional Action"], ["slightly above", "Perception"], ["fiscal 1989 sales", "Reporting"], ["$155 million", "Aspectual"], ["industrial unit", "State"], ["margin pressures", "State"], ["lower demand", "State"], ["$7.8 million", "Aspectual"], ["$13.625", "Aspectual"]]
"""
import json
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tag import pos_tag
from nltk.chunk import ne_chunk
from nltk.tree import Tree
from collections import Counter

# Load the data from the file
with open('data/events.json', 'r') as fp:
   events = json.load(fp)

# Create an empty list for storing the results
results = []

for sentence in events['sentences']:
   # Tokenize the text into words and remove punctuation marks
   tokens = [word for word in word_tokenize(sentence)]
   tokens = [t for t in tokens if not t == ',']
   
   # Remove stopwords
   filtered_tokens = [w for w in tokens if not w in set(stopwords.words())]
   
   # Stem each token using the Porter stemming algorithm
   stems = [PorterStemmer().stem(w) for w in filtered_tokens]
   
   # Tag parts of speech to each token
   tagged_tokens = pos_tag(filtered_tokens)
   
   # Chunk the tagged tokens into named entities
   chunks = ne_chunk(tagged_tokens, binary=True)
   
   # Iterate over all the chunks
   for chunk in chunks:
       # If a chunk is found that contains only one token, add