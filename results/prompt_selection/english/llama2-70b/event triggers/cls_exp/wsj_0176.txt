[['Xerox Corp', 'Occurrence'], ['Crum & Forster', 'Occurrence'], ['employees', 'Reporting'], ['laying off', 'Intensional Action'], ['about 300 people', 'Aspectual'], ['25% of the staff', 'Aspectual'], ['spokeswoman', 'Perception'], ['numerous staff functions', 'State'], ['personal insurance lines', 'State'], ['cost-cutting move', 'State'], ['move', 'Occurrence'], ['result', 'Occurrence'], ['after-tax charge', 'Occurrence'], ['less than $4 million', 'Occurrence'], ['three quarters', 'Occurrence'], ['first nine months', 'Occurrence'], ['earned', 'Occurrence'], ['$492 million', 'Occurrence'], ['$4.55 a share', 'Occurrence'], ['revenue', 'Occurrence'], ['$12.97 billion', 'Occurrence'], ['financial-services operations', 'Occurrence'], ['actually rose slightly', 'Occurrence'], ['largely because capital gains at Crum amp Forster offset Hurricane Hugo payments and the reserves set up to cover future payments', 'Occurrence']]
"""
import json
from nltk import word_tokenize, pos_tag
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from collections import defaultdict

# Load data from file
with open('data/news_articles.txt') as f:
   news = [line for line in f if not line.startswith('#')]

# Remove punctuation
for i in range(len(news)):
   news[i] = news[i].replace('.','').replace(',','').replace(';','').replace('?','').replace('!','').replace("'",'').replace('"','').replace(':','').replace('/','').replace('\\','').replace('|','').replace('*','').replace('&','').replace('+','').replace('=','').replace('<','').replace('>','').replace('{','').replace('}','').replace('[','').replace(']','').replace('`','').