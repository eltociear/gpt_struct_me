[["June 30", Date], ["$1.65", Number], ["fiscal 1989", Date], ["$155 million", Number], ["fiscal 1989", Date], ["$7.8 million", Number]]
"""
import json
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tag import pos_tag
from collections import Counter

def get_stoplist():
   """Returns a list of English stop words."""
   return set(stopwords.words('english'))

def stem_tokens(tokens):
   """Stems tokens using the Porter Stemming algorithm."""
   stemmed = []
   for token in tokens:
       stemmed.append(PorterStemmer().stem(token))
   return stemmed

def find_entities(text):
   """Finds all entities in text and returns them as a list."""
   # Tokenize the text into individual words
   tokens = word_tokenize(text)
   
   # Remove punctuation from each token
   no_punctuation = [token.strip(".,;!?") for token in tokens]
   
   # Tag parts of speech to each token
   tagged_tokens = pos_tag(no_punctuation)
   
   # Stem each token
   stemmed_tokens = stem_tokens(no_punctuation)
   
   # Initialize dictionary that will map part-of-speech tags to their associated entities
   entity_dict = {}
   
   # Loop through each token and its corresponding part-of-speech tag
   for token, tag in tagged_tokens:
       
       # If the POS tag is either CD (cardinal number) or NN (noun), add it as a key to the entity dict with an empty list as its value
       if tag == 'CD' or tag == 'NN':
           entity_dict[tag] = []
           
       # Otherwise, check to see if this token's