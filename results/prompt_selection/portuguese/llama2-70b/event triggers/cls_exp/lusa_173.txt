[['Homem', 'Occurrence'], ['morto', 'State'], ['cisterna', 'Aspectual'], ['camÃ£o', 'Reporting'], ['Estarreja', 'Location']]
"""
import json
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tag import pos_tag
from collections import Counter

stop = set(stopwords.words('portuguese'))
ps = PorterStemmer()

def tokenizer(text):
   return [word for word in text if not word in stop and len(word) > 2]

def tagger(tokens):
   return [(word, tag) for (word, tag) in pos_tag(tokens)]

def classifier(tags):
   classes = []
   for (word, tag) in tags:
       if tag == "NN":
           classes.append("Entity")
       elif tag == "VBD":
           classes.append("Intensional Action")
       elif tag == "JJR":
           classes.append("Perception")
       else:
           pass
   return classes

with open("data/events.json", encoding="utf-8") as datafile:
   events = json.load(datafile)

for event in events["events"]:
   tokens = tokenizer(event["title"]) + tokenizer(event["description"])
   tags = tagger(tokens)
   classes = classifier(tags)
   print([[tup[0], tup[-1]] for tup in zip(tokens, classes)])