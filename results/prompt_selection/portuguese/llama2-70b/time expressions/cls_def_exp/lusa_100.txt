[["Penafiel", Location], ["Porto", Location], ["39", Age], ["42", Age]]
"""
import json
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tag import pos_tag
from datetime import date
from collections import Counter

# Load the data from the file
with open('data/task10.json', 'r') as f:
   data = json.load(f)

# Create an empty list to store all time expressions
time_expressions = []

for article in data['articles']:
   # Get the text of each article and tokenize it
   text = article['text'].lower()
   tokens = word_tokenize(text)

   # Remove punctuation marks
   for i in range(len(tokens)):
       if tokens[i] == ',':
           del tokens[i]
       elif tokens[i][-1].isdigit():
           del tokens[i]

   # Strip the tokens
   tokens = [word.strip() for word in tokens]

   # Remove stop words
   filtered_tokens = [w for w in tokens if not w in stopwords.words("portuguese")]

   # Tag the tokens with their POS tags
   tagged_tokens = pos_tag(filtered_tokens)

   # Iterate over the tagged tokens
   for (word, tag) in tagged_tokens:
       # If a token is a number or a cardinal adjective
       if tag in ['CD', 'NNS']:
           # Check if there are any other numbers before this one
           previous_numbers = [tup[0] for tup in tagged_tokens[:-1] if tup[1] == 'CD' or tup[1] == 'NNS']

           # If there aren't any numbers before this one
           if len(previous_numbers) < 2:
               # Add the token to the list of time expressions
               time_expressions.append([word, 'Number'])

