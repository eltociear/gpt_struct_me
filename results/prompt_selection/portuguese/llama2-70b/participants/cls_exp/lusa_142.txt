[['GNR', 'Organization'], ['Mértola', 'Location']]
"""
import json
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tag import pos_tag
from collections import Counter

# Load the list of classes and their synonyms
with open('classes.json') as fp:
   classes = json.load(fp)

# Initialize the stemmer
ps = PorterStemmer()

def classify(text):
   # Tokenize the text into words
   tokens = [word for sent in text.split('. ') for word in sent.lower().split() if not word in stopwords.words("portuguese")]
   
   # Tag each token with its part-of-speech tag
   tags = [pos_tag([w])[0][1] for w in tokens]
   
   # Stem all tokens
   stems = [ps.stem(t) for t in tokens]
   
   # Classify each token based on its POS tag
   entities = []
   for i, (token, tag, stem) in enumerate(zip(tokens, tags, stems)):
       if tag == 'NNP':
           entities.append((token, 'Person'))
       
       elif tag == 'NNS' or tag == 'NNPS':
           entities.append((token, 'Organization'))
           
       elif tag == 'VBD':
           entities.append((token, 'Facility'))
           
       elif tag == 'JJR':
           entities.append((token, 'Object'))
           
       elif tag == 'CD':
           entities.append((token, 'Location'))
           
       elif tag == 'NN':
           entities.append((token, 'Other'))
           
       else:
           pass
   
   return entities

if __name__ == "__main__":
   print(classify('GNR detém suspeita de tráfico de droga e apreende 12.300 doses de haxixe em Mértola\