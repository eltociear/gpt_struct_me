[['Homem', 'Person'], ['Estarreja', 'Location']]
"""
import json
from nltk import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from collections import Counter

# Load the list of classes and their synonyms
with open('classes.json') as file:
   classes = json.load(file)

# Strip punctuation from text
def stripPunctuation(text):
   return "".join([char for char in text if not char.isdigit()])

# Tokenize words
def tokenizer(text):
   tokens = []
   for sentence in text.split("."):
       tokens += [word for word in word_tokenize(sentence)]
   return tokens

# Remove stopwords
stoplist = set(stopwords.words())
def removeStopWords(tokens):
   return [w for w in tokens if not w in stoplist]

# Stem each word
porter = PorterStemmer()
def stemming(tokens):
   return [porter.stem(t) for t in tokens]

# Get all possible combinations of two adjacent words
def getCombinations(tokens):
   combos = []
   for i in range(len(tokens)-1):
       combos.append((tokens[i], tokens[i+1]))
   return combos

# Classify a combination of two words
def classifier(combo, classes):
   # Check if both words are in the dictionary
   if combo[0].lower() in classes and combo[1].lower() in classes:
       return (combo[0], classes[combo[0]])
   else:
       return None

# Main function
def extractEntities(text):
   # Strip punctuation from text
   strippedText = stripPunctuation(text).lower()
   
   # Tokenize words
   tokens = tokenizer(strippedText)
   
   # Remove stopwords
   filteredTokens = removeStopWords(tokens)
   
  